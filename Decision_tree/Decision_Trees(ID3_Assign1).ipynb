{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pprint\n",
    "import ipdb\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load training data, split into train and validation sets\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "train_data = data.sample(frac=0.8)\n",
    "val_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_before_split(train_data):\n",
    "    \"\"\" Finds Entropy of dataset before any split \"\"\"\n",
    "    \n",
    "    dependent_variable = \"left\"\n",
    "    entropy = 0\n",
    "    labels = train_data[dependent_variable].unique()\n",
    "    for label in labels:\n",
    "        temp = train_data[dependent_variable].value_counts()[label] / len(train_data[dependent_variable])\n",
    "        entropy += -temp * log(temp + eps)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_on_attribute_split(train_data, attribute):\n",
    "    \"\"\" Finds resulting entropy of dataset if it is split using attribute \"\"\"\n",
    "    entropy_after_split = 0\n",
    "    dependent_variable = \"left\"\n",
    "    class_labels = train_data[dependent_variable].unique()\n",
    "    attribute_labels = train_data[attribute].unique()\n",
    "\n",
    "    for attribute_label in attribute_labels:\n",
    "        entropy = 0\n",
    "        for class_label in class_labels:\n",
    "            numer = len(train_data[attribute][train_data[attribute] == attribute_label][train_data[dependent_variable] == class_label])\n",
    "            denom = len(train_data[attribute][train_data[attribute] == attribute_label])\n",
    "            temp = numer / (denom + eps)\n",
    "            entropy += -temp * log(temp + eps)\n",
    "        temp2 = denom / len(train_data)\n",
    "        entropy_after_split += -temp2 * entropy\n",
    "    return abs(entropy_after_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_criteria(train_data):\n",
    "    \"\"\" Finds the best attribute to split on \"\"\"\n",
    "    \n",
    "    # Define categorical attributes\n",
    "    attributes = [\"Work_accident\", \"promotion_last_5years\", \"sales\", \"salary\"]    \n",
    "    Info_gain = {}\n",
    "    for key in attributes:\n",
    "        Info_gain[key] = entropy_before_split(train_data) - entropy_on_attribute_split(train_data, key)\n",
    "    first = max(Info_gain, key=lambda k: Info_gain[k])\n",
    "#     print (Info_gain)\n",
    "    return first, Info_gain[first]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_data, feature, label):\n",
    "    \"\"\" This splits the dataset on given feature and all of its values \"\"\"\n",
    "    return train_data[train_data[feature] == label].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_probable(train_data):\n",
    "    dependent_variable = \"left\"\n",
    "    count_left = len(train_data[train_data[dependent_variable] == 0])\n",
    "    count_right = len(train_data[train_data[dependent_variable] == 1])\n",
    "    if count_left > count_right:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_tree(train_data):\n",
    "    \"\"\" Builds tree recursively \"\"\"\n",
    "    D_tree = {}\n",
    "    dependent_variable = \"left\"\n",
    "    root, gain = split_criteria(train_data)\n",
    "    \n",
    "    if gain == 0.0:\n",
    "        return most_probable(train_data)\n",
    "    \n",
    "    labels = train_data[root].unique()\n",
    "    D_tree[root] = {}\n",
    "    \n",
    "    for label in labels:\n",
    "        split_data = split_dataset(train_data, root, label)\n",
    "        unique_labels = split_data[dependent_variable].unique()\n",
    "        \n",
    "        if len(unique_labels) == 1:\n",
    "            D_tree[root][label] = unique_labels[0]\n",
    "        else:\n",
    "            D_tree[root][label] = Decision_tree(split_data)\n",
    "    return D_tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst,tree):\n",
    "    #This function is used to predict for any input variable  \n",
    "    #Recursively we go through the tree that we built earlier\n",
    "    for nodes in tree.keys():        \n",
    "        \n",
    "        value = inst[nodes]\n",
    "        tree = tree[nodes][value]\n",
    "        prediction = 0\n",
    "            \n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(inst, tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break;                            \n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def validate_tree(val_data):\n",
    "    tree = Decision_tree(train_data)\n",
    "    predicted = []\n",
    "    for index, row in val_data.iterrows():\n",
    "        predicted.append(predict(row, tree))\n",
    "    actual = val_data[\"left\"].tolist()\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for i in range(0, len(predicted)):\n",
    "        if (predicted[i] == 0 and actual[i] == 0):\n",
    "            true_neg += 1\n",
    "        elif (predicted[i] == 0 and actual[i] == 1):\n",
    "            false_neg += 1\n",
    "        elif (predicted[i] == 1 and actual[i] == 0):\n",
    "            false_pos += 1\n",
    "        else:\n",
    "            true_pos += 1\n",
    "    return true_pos, true_neg, false_pos, false_neg \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(val_data):\n",
    "    true_pos, true_neg, false_pos, false_neg = validate_tree(val_data)\n",
    "    total_instances = true_neg + true_pos + false_neg + false_pos\n",
    "    accuracy_estimate = (true_neg + true_pos) / (total_instances)\n",
    "    precision_estimate = true_pos / (true_pos + false_pos)\n",
    "    recall_estimate = (true_pos) / (true_pos + false_neg)\n",
    "    f1_score = (1 / recall_estimate) + (1 / precision_estimate)\n",
    "    f1_score = 2 / f1_score\n",
    "    print (\"Accuracy : \", accuracy_estimate)\n",
    "    print (\"Precision : \", precision_estimate)\n",
    "    print (\"Recall : \", recall_estimate)\n",
    "    print (\"F1_Score : \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7682384341637011\n",
      "Precision :  1.0\n",
      "Recall :  0.0019157088122605363\n",
      "F1_Score :  0.0038240917782026767\n"
     ]
    }
   ],
   "source": [
    "accuracy(val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
