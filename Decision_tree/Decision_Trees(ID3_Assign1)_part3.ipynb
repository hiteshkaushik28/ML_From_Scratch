{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import ipdb\n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load training data, split into train and validation sets\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "train_data = data.sample(frac=0.8)\n",
    "val_data = data.drop(train_data.index)\n",
    "discrete_attributes = [\"Work_accident\", \"promotion_last_5years\", \"sales\", \"salary\"]    \n",
    "real_attributes = [\"satisfaction_level\", \"last_evaluation\", \"number_project\", \"average_montly_hours\", \"time_spend_company\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_before_split(train_data):\n",
    "    \"\"\" Finds Entropy of dataset before any split \"\"\"\n",
    "    \n",
    "    dependent_variable = \"left\"\n",
    "    count_0 = len(train_data[train_data[dependent_variable] == 0])\n",
    "    total = len(train_data[dependent_variable])\n",
    "    ratio = count_0 / total\n",
    "    gini = 2 * (ratio) * (1 - ratio)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_on_real_attribute_split(train_data,attribute):\n",
    "    Class = \"left\" \n",
    "    class_labels = train_data[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "    attribute_labels = train_data[attribute].unique()  #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "    class_labels.sort()\n",
    "    attribute_labels.sort()\n",
    "    combined = pd.DataFrame(train_data,columns=[attribute,'left']).sort_values(by=[attribute,'left'])\n",
    "    \n",
    "    split_node_gini = None\n",
    "    split_node = None\n",
    "    np_array_length = len(combined)\n",
    "    total0 = len(combined[combined['left'] == 0])\n",
    "    total1 = np_array_length - total0\n",
    "    count0 = 0\n",
    "    i = 0\n",
    "    previous = None\n",
    "    for row in combined.iterrows():\n",
    "        if (i != 0 and previous != row[1][attribute]):\n",
    "            gini = 0\n",
    "            gini2 = 0\n",
    "            num = count0 \n",
    "            den = i\n",
    "            temp = num / (den)\n",
    "            gini += 2 * temp * (1 - temp)\n",
    "            \n",
    "            temp2 = den/np_array_length\n",
    "            gini2 += temp2*gini\n",
    "            \n",
    "            gini = 0\n",
    "            num = total0 - count0 #for > 0's\n",
    "            den = np_array_length - i\n",
    "            temp = num / (den+eps)\n",
    "            gini += 2 * temp * (1 - temp)\n",
    "            \n",
    "            temp2 = den/np_array_length\n",
    "            gini2 += temp2*gini\n",
    "            \n",
    "            if(split_node_gini == None):\n",
    "                split_node_gini = abs(gini2)\n",
    "                split_node = previous\n",
    "            else:\n",
    "                if(split_node_gini > abs(gini2)):\n",
    "                    split_node_gini = abs(gini2)\n",
    "                    split_node = previous\n",
    "        if (row[1]['left']==0):\n",
    "            count0 += 1\n",
    "        previous = row[1][attribute]\n",
    "        i += 1\n",
    "        \n",
    "    gini = 0\n",
    "    gini2 = 0\n",
    "    num = count0 #for <= 0's\n",
    "    den = i\n",
    "    temp = num / (den)\n",
    "    gini += 2 * temp * (1 - temp)\n",
    "    \n",
    "    temp2 = den/np_array_length\n",
    "    gini2 += temp2 * gini\n",
    "\n",
    "    gini = 0\n",
    "    num = total0 - count0 #for > 0's\n",
    "    den = np_array_length - i\n",
    "    temp = num / (den+eps)\n",
    "    gini += 2 * temp * (1 - temp)\n",
    "    \n",
    "    temp2 = den/np_array_length\n",
    "    gini2 += temp2 * gini\n",
    "\n",
    "    if(split_node_gini == None):\n",
    "        split_node_gini = abs(gini2)\n",
    "        split_node = previous\n",
    "    else:\n",
    "        if(split_node_gini > abs(gini2)):\n",
    "            split_node_gini = abs(gini2)\n",
    "            split_node = previous\n",
    "#     print (split_node,split_node_entropy)\n",
    "    return split_node_gini, split_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2618944129979286, 0.46)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_on_real_attribute_split(train_data, \"satisfaction_level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_on_discrete_attribute_split(train_data, attribute):\n",
    "    \"\"\" Finds resulting entropy of dataset if it is split using attribute \"\"\"\n",
    "    gini_after_split = 0\n",
    "    dependent_variable = \"left\"\n",
    "    attribute_labels = train_data[attribute].unique()\n",
    "\n",
    "    for attribute_label in attribute_labels:\n",
    "        gini = 0\n",
    "        numer = len(train_data[attribute][train_data[attribute] == attribute_label][train_data[dependent_variable] == 0])\n",
    "        denom = len(train_data[attribute][train_data[attribute] == attribute_label])\n",
    "        temp = numer / (denom + eps)\n",
    "        gini = 2 * temp * (1 -  temp)\n",
    "        temp2 = denom / (len(train_data) + eps)\n",
    "        gini_after_split += temp2 * gini\n",
    "    return abs(gini_after_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_criteria(train_data):\n",
    "    \"\"\" Finds the best attribute to split on \"\"\"\n",
    "    \n",
    "    Info_gain_discrete = {}\n",
    "    initialEntropy = entropy_before_split(train_data)\n",
    "    Info_gain = None\n",
    "    split_point = None\n",
    "    max_gain_attribute = None\n",
    "    \n",
    "    for key in discrete_attributes:\n",
    "        Info_gain_discrete[key] = initialEntropy - entropy_on_discrete_attribute_split(train_data, key)\n",
    "        \n",
    "    for key in real_attributes:\n",
    "        max_entropy, max_entropy_val = entropy_on_real_attribute_split(train_data, key)\n",
    "        if (Info_gain == None or initialEntropy - max_entropy > Info_gain):\n",
    "            Info_gain = initialEntropy - max_entropy\n",
    "            split_point = max_entropy_val\n",
    "            max_gain_attribute = key\n",
    "             \n",
    "    first = max(Info_gain_discrete, key=lambda k: Info_gain_discrete[k])\n",
    "    if Info_gain_discrete[first] > Info_gain:\n",
    "        Info_gain = Info_gain_discrete[first]\n",
    "        max_gain_attribute = first\n",
    "    return Info_gain, max_gain_attribute, split_point\n",
    "    return Info_gain_discrete[first], first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_smaller(train_data, feature, split_point):\n",
    "    return train_data[train_data[feature] <= split_point].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_greater(train_data, feature, split_point):\n",
    "      return train_data[train_data[feature] > split_point].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_data, feature, label):\n",
    "    \"\"\" This splits the dataset on given feature and all of its values \"\"\"\n",
    "    return train_data[train_data[feature] == label].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_probable(train_data):\n",
    "    dependent_variable = \"left\"\n",
    "    count_left = len(train_data[train_data[dependent_variable] == 0])\n",
    "    count_right = len(train_data[train_data[dependent_variable] == 1])\n",
    "    if count_left > count_right:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_tree(train_data):\n",
    "    \"\"\" Builds tree recursively \"\"\"\n",
    "    \n",
    "    D_tree = {}\n",
    "    dependent_variable = \"left\"\n",
    "    Info_gain, root, split_point = split_criteria(train_data)\n",
    "#     print (Info_gain, root, split_point)\n",
    "    if Info_gain == 0.0:\n",
    "        return most_probable(train_data)\n",
    "    \n",
    "    D_tree[root] = {}\n",
    "    \n",
    "    if root in (discrete_attributes):\n",
    "        labels = train_data[root].unique()\n",
    "        for label in labels:\n",
    "            split_data = split_dataset(train_data, root, label)\n",
    "            unique_labels = split_data[dependent_variable].unique()\n",
    "            if len(unique_labels) == 1:\n",
    "                D_tree[root][label] = unique_labels[0]\n",
    "            else:\n",
    "                D_tree[root][label] = Decision_tree(split_data)\n",
    "        return D_tree\n",
    "\n",
    "    else:\n",
    "        split_data = split_dataset_smaller(train_data, root, split_point)\n",
    "        unique_labels = split_data[dependent_variable].unique()\n",
    "        if len(unique_labels) == 1:\n",
    "            D_tree[root][split_point] = unique_labels[0]\n",
    "        else:\n",
    "            D_tree[root][split_point] = Decision_tree(split_data)\n",
    "            \n",
    "        split_data = split_dataset_greater(train_data, root, split_point)\n",
    "        unique_labels = split_data[dependent_variable].unique()\n",
    "        if len(unique_labels) == 1:\n",
    "            D_tree[root][split_point + 0.000000001] = unique_labels[0]\n",
    "        else:\n",
    "            D_tree[root][split_point + 0.000000001] = Decision_tree(split_data)\n",
    "    \n",
    "        return D_tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst, tree):\n",
    "    for nodes in tree.keys():        \n",
    "        value = inst[nodes]\n",
    "        if nodes in discrete_attributes:\n",
    "            if value in list((tree[nodes]).keys()):\n",
    "                tree = tree[nodes][value]\n",
    "            else:\n",
    "                zeros = 0\n",
    "                ones = 0\n",
    "                for i in tree[nodes].keys():\n",
    "                    if tree[nodes][i] == 0:\n",
    "                        zeros += 1\n",
    "                    elif tree[nodes][i] == 1:\n",
    "                        ones += 1\n",
    "                if zeros > ones:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return 1\n",
    "\n",
    "        elif nodes in real_attributes:\n",
    "            first_key = list(tree[nodes].keys())[0]\n",
    "            if value <= first_key :\n",
    "                tree = tree[nodes][first_key]\n",
    "            else:\n",
    "                second_key = list(tree[nodes].keys())[1]\n",
    "                tree = tree[nodes][second_key]\n",
    "        prediction = 0\n",
    "\n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(inst, tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break;\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(inst, tree):\n",
    "#     #This function is used to predict for any input variable  \n",
    "#     #Recursively we go through the tree that we built earlier\n",
    "#     for nodes in tree.keys():        \n",
    "#         value = inst[nodes]\n",
    "#         if nodes in discrete_attributes:\n",
    "#             if value not in tree.keys():\n",
    "#                 count_left = 0\n",
    "#                 count_right = 1\n",
    "#                 for i in tree[nodes].values():\n",
    "#                     if (type(i) != dict):\n",
    "#                         if(i == 1):\n",
    "#                             count_right += 1\n",
    "#                         else:\n",
    "#                             count_left += 0\n",
    "#                 return max(count_left, count_right)\n",
    "#             else:\n",
    "#                 tree = tree[nodes][value]\n",
    "#         else:\n",
    "#             if (value <= list((tree[nodes]).keys())[0]):\n",
    "#                 tree = tree[nodes][list((tree[nodes]).keys())[0]]\n",
    "#             else:\n",
    "#                 tree = tree[nodes][list((tree[nodes]).keys())[1]]\n",
    "#         prediction = 0\n",
    "#         if type(tree) is dict:\n",
    "#             prediction = predict(inst, tree)\n",
    "#         else:\n",
    "#             prediction = tree\n",
    "#             break;                            \n",
    "        \n",
    "#     return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def validate_tree(val_data, tree):\n",
    "    predicted = []\n",
    "    for index, row in val_data.iterrows():\n",
    "        predicted.append(predict(row, tree))\n",
    "    actual = val_data[\"left\"].tolist()\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for i in range(0, len(predicted)):\n",
    "        if (predicted[i] == 0 and actual[i] == 0):\n",
    "            true_neg += 1\n",
    "        elif (predicted[i] == 0 and actual[i] == 1):\n",
    "            false_neg += 1\n",
    "        elif (predicted[i] == 1 and actual[i] == 0):\n",
    "            false_pos += 1\n",
    "        else:\n",
    "            true_pos += 1\n",
    "    return true_pos, true_neg, false_pos, false_neg \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(val_data, tree):\n",
    "    true_pos, true_neg, false_pos, false_neg = validate_tree(val_data, tree)\n",
    "#     print (true_pos, true_neg, false_pos, false_neg)\n",
    "    total_instances = true_neg + true_pos + false_neg + false_pos\n",
    "    accuracy_estimate = (true_neg + true_pos) / (total_instances)\n",
    "    precision_estimate = true_pos / (true_pos + false_pos)\n",
    "    recall_estimate = (true_pos) / (true_pos + false_neg)\n",
    "    f1_score = (1 / recall_estimate) + (1 / precision_estimate)\n",
    "    f1_score = 2 / f1_score\n",
    "    print (\"Accuracy : \", accuracy_estimate)\n",
    "    print (\"Precision : \", precision_estimate)\n",
    "    print (\"Recall : \", recall_estimate)\n",
    "    print (\"F1_Score : \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7602313167259787\n",
      "Precision :  0.490547263681592\n",
      "Recall :  0.948076923076923\n",
      "F1_Score :  0.6465573770491803\n"
     ]
    }
   ],
   "source": [
    "tree = Decision_tree(train_data)\n",
    "accuracy(val_data, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
